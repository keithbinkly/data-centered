<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>data-centered | Library Updates</title>
    <link>https://data-centered.com</link>
    <description>Synthesis and analysis of curated resources on knowledge engineering, semantic layers, data visualization, and AI-ready data infrastructure.</description>
    <language>en-us</language>
    <lastBuildDate>Sun, 12 Jan 2026 00:00:00 GMT</lastBuildDate>
    <atom:link href="https://data-centered.com/feed.xml" rel="self" type="application/rss+xml"/>

    <item>
      <title>Library Update #6: January 2026</title>
      <link>https://data-centered.com/synthesis/update-006-jan-2026</link>
      <guid isPermaLink="true">https://data-centered.com/synthesis/update-006-jan-2026</guid>
      <pubDate>Sun, 12 Jan 2026 00:00:00 GMT</pubDate>
      <description>52 resources added. This intake session surfaced a fascinating tension: we're simultaneously building semantic infrastructure for AI agents AND realizing our existing foundations are shakier than we thought. Knowledge engineering is eating data engineering—multiple authors converging on the same conclusion that the warehouse/lake distinction is collapsing into "structured knowledge systems."</description>
      <content:encoded><![CDATA[
        <p>This intake session surfaced a fascinating tension: we're simultaneously building semantic infrastructure for AI agents AND realizing our existing foundations are shakier than we thought.</p>
        <p>Knowledge engineering is eating data engineering—multiple authors converging on the same conclusion that the warehouse/lake distinction is collapsing into "structured knowledge systems." Meanwhile, the agent tooling explosion (8 new repos for agent infrastructure alone) reveals a gap: sophisticated orchestration layers on semantic models that don't exist yet.</p>
        <p>Bergevin's "Figma Moment" thesis resonates across resources—we're at the hand-coding HTML stage of semantic work.</p>
        <p><strong>52 resources processed</strong> across knowledge-engineering, ai-tools, analytics-engineering, and data-visualization.</p>
      ]]></content:encoded>
    </item>

    <item>
      <title>Library Update #5: New Year Knowledge Sprint</title>
      <link>https://data-centered.com/synthesis/update-005-jan-02-2026</link>
      <guid isPermaLink="true">https://data-centered.com/synthesis/update-005-jan-02-2026</guid>
      <pubDate>Thu, 02 Jan 2026 00:00:00 GMT</pubDate>
      <description>31 resources added. The semantic layer debate went mainstream as MotherDuck asked "do we even need this?" while Shopify's taxonomy success answered "yes, if you're building for scale." Context graphs emerged as a bridge concept. MCP moved from spec to infrastructure.</description>
      <content:encoded><![CDATA[
        <p>New year, new paradigm. The semantic layer debate went mainstream as MotherDuck asked "do we even need this?" while Shopify's taxonomy success answered "yes, if you're building for scale."</p>
        <p>Context graphs emerged as a bridge concept—neither pure knowledge graph (too academic) nor pure semantic layer (too metrics-focused). MCP moved from spec to infrastructure with MotherDuck shipping a production server.</p>
        <p>Three different projects tackled cross-session memory, confirming it's the unsolved frontier. The Inmon-Kimball architecture debate got a sequel, reframed for the AI age.</p>
        <p><strong>31 resources processed</strong> across knowledge-engineering and ai-tools.</p>
      ]]></content:encoded>
    </item>

    <item>
      <title>Library Update #4: Year-End Semantic Reckoning</title>
      <link>https://data-centered.com/synthesis/update-004-dec-26-2025</link>
      <guid isPermaLink="true">https://data-centered.com/synthesis/update-004-dec-26-2025</guid>
      <pubDate>Fri, 26 Dec 2025 00:00:00 GMT</pubDate>
      <description>9 resources added. A focused batch that crystallized the semantic infrastructure thesis. The "Figma moment" insight: we're hand-coding semantic models with no visual tools, version control patterns, or component marketplace.</description>
      <content:encoded><![CDATA[
        <p>A focused batch that crystallized the semantic infrastructure thesis. The debate sharpened: MotherDuck asks "do we need this complexity?" while Shopify's success answers "yes, at scale" and Vashishta warns "but most attempts will fail anyway."</p>
        <p>Bergevin explains why: the tooling sucks. His "Figma moment" thesis is the most actionable insight—we're hand-coding semantic models with no visual tools, version control patterns, or component marketplace.</p>
        <p>Whoever builds "Figma for semantics" unlocks the next wave.</p>
        <p><strong>9 resources processed</strong> in knowledge-engineering.</p>
      ]]></content:encoded>
    </item>

    <item>
      <title>Library Update #3: The Pudding Deep Dive &amp; Semantic Layer Foundations</title>
      <link>https://data-centered.com/synthesis/update-003-dec-19-21-2025</link>
      <guid isPermaLink="true">https://data-centered.com/synthesis/update-003-dec-19-21-2025</guid>
      <pubDate>Sun, 21 Dec 2025 00:00:00 GMT</pubDate>
      <description>51 resources added. Infrastructure week. The Pudding's entire production stack decoded: SvelteKit + Scrollama + Layer Cake. dbt's semantic layer documentation went comprehensive. Official AI learning platforms catalogued.</description>
      <content:encoded><![CDATA[
        <p>Infrastructure week. The Pudding's entire production stack decoded: SvelteKit + Scrollama + Layer Cake, with open-sourced templates, data, and the whole site architecture. For scrollytelling, start here.</p>
        <p>Simultaneously, dbt's semantic layer documentation went from sparse to comprehensive—architecture, exports, time spine patterns all documented.</p>
        <p>The official AI learning platforms from OpenAI, Anthropic, and Google got catalogued. Memory solutions are fragmenting with no clear winner. Karpathy's 1-hour LLM intro remains the best single-resource introduction.</p>
        <p><strong>51 resources processed</strong> across data-visualization, analytics-engineering, and ai-tools.</p>
      ]]></content:encoded>
    </item>

    <item>
      <title>Library Update #2: December Expansion</title>
      <link>https://data-centered.com/synthesis/update-002-dec-13-17-2025</link>
      <guid isPermaLink="true">https://data-centered.com/synthesis/update-002-dec-13-17-2025</guid>
      <pubDate>Wed, 17 Dec 2025 00:00:00 GMT</pubDate>
      <description>40 resources added. The batch that established the knowledge base's character. The Pudding's process series, context engineering foundations, Tableau exemplars, and agent memory research.</description>
      <content:encoded><![CDATA[
        <p>The batch that established the knowledge base's character. The Pudding's "How to Make Dope Shit" series set the standard for data storytelling methodology. Context engineering crystallized as LangChain and Weaviate both published foundational content—the term went from buzzword to discipline.</p>
        <p>Tableau's Visual Vocabulary and chart catalogs captured the craft knowledge that doesn't fit in documentation. Agent memory research emerged with four different approaches in one batch—the problem is clear, the solution isn't.</p>
        <p>MCP became "the USB-C layer for AI."</p>
        <p><strong>40 resources processed</strong> across data-visualization, knowledge-engineering, and ai-tools.</p>
      ]]></content:encoded>
    </item>

    <item>
      <title>Library Update #1: Foundations</title>
      <link>https://data-centered.com/synthesis/update-001-dec-2024</link>
      <guid isPermaLink="true">https://data-centered.com/synthesis/update-001-dec-2024</guid>
      <pubDate>Fri, 13 Dec 2024 00:00:00 GMT</pubDate>
      <description>27 resources added. The seed collection that defined the thesis: data infrastructure isn't AI-ready because of missing meaning, not missing pipelines. Jessica Talisman's knowledge engineering curriculum became the backbone.</description>
      <content:encoded><![CDATA[
        <p>Where it started. The seed collection that defined the thesis: data infrastructure isn't AI-ready because of missing meaning, not missing pipelines.</p>
        <p>Jessica Talisman's knowledge engineering curriculum—controlled vocabularies through ontologies to metadata modeling—became the backbone. The "semantic gap" got named by multiple authors from different angles. dbt's semantic layer documentation provided the practical implementation.</p>
        <p>Library science wisdom ("the reference interview") offered unexpected insight. The foundation thesis: making data AI-ready is about encoding meaning, not scaling storage.</p>
        <p><strong>27 resources processed</strong> across knowledge-engineering and analytics-engineering.</p>
      ]]></content:encoded>
    </item>

  </channel>
</rss>
